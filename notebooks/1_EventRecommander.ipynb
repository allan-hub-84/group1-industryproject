{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d68fde13-f5be-45fe-964f-5ce3f0c98987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../utilities'))\n",
    "import global_utils\n",
    "\n",
    "# Data Manipulation and Analysis\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns  \n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import joblib\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beb555fc-f6e0-4581-92fd-9b37e3713460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = global_utils.import_csv('./../data/customer1.csv')\n",
    "global_utils.define_df_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "424a95e6-82d2-45e4-ad6a-5168950d84a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   customer_ID  500 non-null    int64 \n",
      " 1   first_name   500 non-null    object\n",
      " 2   last_name    500 non-null    object\n",
      " 3   email        500 non-null    object\n",
      " 4   question_1   500 non-null    object\n",
      " 5   question_2   500 non-null    object\n",
      " 6   question_3   500 non-null    object\n",
      " 7   question_4   500 non-null    object\n",
      " 8   question_5   500 non-null    object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 35.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99496a69-bb3e-463f-8787-93a2a51e2b0e",
   "metadata": {},
   "source": [
    "Let's PreProcess the data and and combine all of our questions column into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "703e2e84-6ae7-4eb0-9483-f7a0eaebcb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>question_3</th>\n",
       "      <th>question_4</th>\n",
       "      <th>question_5</th>\n",
       "      <th>questions_concat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>Abigail</td>\n",
       "      <td>Lewis</td>\n",
       "      <td>abigail.lewis1000001@example.com</td>\n",
       "      <td>Walking, Jogging, Pilates</td>\n",
       "      <td>2–3 days</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Weight Loss, Improve Health, Training</td>\n",
       "      <td>Walking Jogging Pilates 2–3 days Lunch Medium Weight Loss Improve Health Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002</td>\n",
       "      <td>Mason</td>\n",
       "      <td>Brown</td>\n",
       "      <td>mason.brown1000002@example.com</td>\n",
       "      <td>Jogging, Walking, Running</td>\n",
       "      <td>0–1 days</td>\n",
       "      <td>Mid-Morning</td>\n",
       "      <td>High</td>\n",
       "      <td>Social, Reduce Stress, Build Strength</td>\n",
       "      <td>Jogging Walking Running 0–1 days Mid-Morning High Social Reduce Stress Build Strength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003</td>\n",
       "      <td>David</td>\n",
       "      <td>Jones</td>\n",
       "      <td>david.jones1000003@example.com</td>\n",
       "      <td>Hiking, Cycling, Walking</td>\n",
       "      <td>2–3 days</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Social, Weight Loss, Build Strength</td>\n",
       "      <td>Hiking Cycling Walking 2–3 days Lunch Medium Social Weight Loss Build Strength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>Liam</td>\n",
       "      <td>Martin</td>\n",
       "      <td>liam.martin1000004@example.com</td>\n",
       "      <td>Running, Group Fitness Class, Hiking</td>\n",
       "      <td>4–5 days</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>Low</td>\n",
       "      <td>Improve Health, Training, Social</td>\n",
       "      <td>Running Group Fitness Class Hiking 4–5 days Lunch Low Improve Health Training Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000005</td>\n",
       "      <td>Samuel</td>\n",
       "      <td>Perez</td>\n",
       "      <td>samuel.perez1000005@example.com</td>\n",
       "      <td>Running, Swimming, Jogging</td>\n",
       "      <td>4–5 days</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>High</td>\n",
       "      <td>Training, Build Strength, Social</td>\n",
       "      <td>Running Swimming Jogging 4–5 days Lunch High Training Build Strength Social</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_ID first_name last_name                             email  \\\n",
       "0      1000001    Abigail     Lewis  abigail.lewis1000001@example.com   \n",
       "1      1000002      Mason     Brown    mason.brown1000002@example.com   \n",
       "2      1000003      David     Jones    david.jones1000003@example.com   \n",
       "3      1000004       Liam    Martin    liam.martin1000004@example.com   \n",
       "4      1000005     Samuel     Perez   samuel.perez1000005@example.com   \n",
       "\n",
       "                             question_1 question_2   question_3 question_4  \\\n",
       "0             Walking, Jogging, Pilates   2–3 days        Lunch     Medium   \n",
       "1             Jogging, Walking, Running   0–1 days  Mid-Morning       High   \n",
       "2              Hiking, Cycling, Walking   2–3 days        Lunch     Medium   \n",
       "3  Running, Group Fitness Class, Hiking   4–5 days        Lunch        Low   \n",
       "4            Running, Swimming, Jogging   4–5 days        Lunch       High   \n",
       "\n",
       "                              question_5  \\\n",
       "0  Weight Loss, Improve Health, Training   \n",
       "1  Social, Reduce Stress, Build Strength   \n",
       "2    Social, Weight Loss, Build Strength   \n",
       "3       Improve Health, Training, Social   \n",
       "4       Training, Build Strength, Social   \n",
       "\n",
       "                                                                        questions_concat  \n",
       "0      Walking Jogging Pilates 2–3 days Lunch Medium Weight Loss Improve Health Training  \n",
       "1  Jogging Walking Running 0–1 days Mid-Morning High Social Reduce Stress Build Strength  \n",
       "2         Hiking Cycling Walking 2–3 days Lunch Medium Social Weight Loss Build Strength  \n",
       "3   Running Group Fitness Class Hiking 4–5 days Lunch Low Improve Health Training Social  \n",
       "4            Running Swimming Jogging 4–5 days Lunch High Training Build Strength Social  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_cols = [f\"question_{i}\" for i in range(1, 6)]\n",
    "\n",
    "df[\"questions_concat\"] = (\n",
    "    df[q_cols]\n",
    "      .fillna(\"\")                                             \n",
    "      .apply(lambda row: \" \".join(str(v).replace(\",\", \" \").strip() \n",
    "                                  for v in row), axis=1)      \n",
    "      .str.replace(r\"\\s+\", \" \", regex=True)                   \n",
    "      .str.strip()                                            \n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1893bf0-4a97-4c1a-a894-e51e105e8aaa",
   "metadata": {},
   "source": [
    "Now we will vectorize our newly created combined coulmn using the TF-IDF vectorizer. It will help us to compare the coine similarity between the new user and the existing user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fc63f26-dae8-406f-aae6-388141293753",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = \"english\")\n",
    "TF_IDF_matrix = vectorizer.fit_transform(df['questions_concat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f14de98-65bf-4e4b-b532-7faf0607e56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 31)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_IDF_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60cf881-18d7-4bf8-a765-32633e592f05",
   "metadata": {},
   "source": [
    "As we can see after vectorizing process we have 31 features to work with.\n",
    "\n",
    "Let's print the cosine-similarity between our existing users as a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4583969-540d-48dc-b07d-2434a2fd528f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 499)\t0.3705929112443899\n",
      "  (0, 496)\t0.18985349864472761\n",
      "  (0, 493)\t0.13163467550385777\n",
      "  (0, 486)\t0.27857192728721647\n",
      "  (0, 478)\t0.41405733929484523\n",
      "  (0, 475)\t0.1651826263479633\n",
      "  (0, 474)\t0.3447717399500473\n",
      "  (0, 461)\t0.4982390235957516\n",
      "  (0, 458)\t0.2281801712827467\n",
      "  (0, 457)\t0.38278131213864647\n",
      "  (0, 455)\t0.5567777876227006\n",
      "  (0, 454)\t0.19137238340199075\n",
      "  (0, 453)\t0.28773565397146295\n",
      "  (0, 450)\t0.3075841389087709\n",
      "  (0, 437)\t0.3375334564327407\n",
      "  (0, 435)\t0.46178131350020424\n",
      "  (0, 433)\t0.07547989632032162\n",
      "  (0, 432)\t0.22546100473459718\n",
      "  (0, 426)\t0.1479200283954869\n",
      "  (0, 422)\t0.3679363272178139\n",
      "  (0, 418)\t0.42356526270648087\n",
      "  (0, 417)\t0.22387126650374126\n",
      "  (0, 413)\t0.07318285736133794\n",
      "  (0, 409)\t0.3144668803255763\n",
      "  (0, 407)\t0.24911537267447703\n",
      "  :\t:\n",
      "  (499, 24)\t0.6023774059886153\n",
      "  (499, 23)\t0.5261575490396135\n",
      "  (499, 22)\t0.41217493144443346\n",
      "  (499, 21)\t0.47181749357103336\n",
      "  (499, 20)\t0.2904441780867202\n",
      "  (499, 19)\t0.1723906514821607\n",
      "  (499, 18)\t0.3998964333093258\n",
      "  (499, 17)\t0.23116658577656377\n",
      "  (499, 16)\t0.30084114152535824\n",
      "  (499, 15)\t0.5140977124008174\n",
      "  (499, 14)\t0.3657960424590732\n",
      "  (499, 13)\t0.3788894076986349\n",
      "  (499, 12)\t0.40572474975548234\n",
      "  (499, 11)\t0.23991399582516312\n",
      "  (499, 10)\t0.25365398842127374\n",
      "  (499, 9)\t0.4644079418637216\n",
      "  (499, 8)\t0.6392394529003975\n",
      "  (499, 7)\t0.453897118489626\n",
      "  (499, 6)\t0.19795116980198013\n",
      "  (499, 5)\t0.704078540051716\n",
      "  (499, 4)\t0.21090566209944112\n",
      "  (499, 3)\t0.27646411373075713\n",
      "  (499, 2)\t0.4488661638911422\n",
      "  (499, 1)\t0.19780776194589914\n",
      "  (499, 0)\t0.3705929112443899\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(TF_IDF_matrix,dense_output=False)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e947e423-298c-44da-816d-0a1306d9b365",
   "metadata": {},
   "source": [
    "Also try to compare the couple of users with their using the cosine-similarity to check how our matrix is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70b77556-9ee9-4226-812d-26f33d450627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: [[0.27819005]]\n"
     ]
    }
   ],
   "source": [
    "user_1 = TF_IDF_matrix[(df['customer_ID'] == 1000001).values,]\n",
    "user_2 = TF_IDF_matrix[(df['customer_ID'] == 1000002).values,]\n",
    "\n",
    "print(\"Similarity:\", cosine_similarity(user_1, user_2))\n",
    "                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eae31b2e-cb2e-4372-9f7b-d0aefea5d4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: [[0.50057243]]\n"
     ]
    }
   ],
   "source": [
    "user_1 = TF_IDF_matrix[(df['customer_ID'] == 1000001).values,]\n",
    "user_3 = TF_IDF_matrix[(df['customer_ID'] == 1000003).values,]\n",
    "\n",
    "print(\"Similarity:\", cosine_similarity(user_1, user_3))                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53f83a73-2f69-420e-9097-061ccf309684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column based upon the index\n",
    "customer_index = df[df['customer_ID'] == 1000001].index\n",
    "\n",
    "# Create a dataframe with the movie titles\n",
    "sim_df = pd.DataFrame({'customer_ID':df['customer_ID'],\n",
    "                       'similarity': np.array(similarity[customer_index, :].todense()).squeeze()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e1ab621b-ded0-4462-b9aa-77242a2391e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1000063</td>\n",
       "      <td>0.750298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1000093</td>\n",
       "      <td>0.708946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1000162</td>\n",
       "      <td>0.714471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1000201</td>\n",
       "      <td>0.759645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1000246</td>\n",
       "      <td>0.701282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1000308</td>\n",
       "      <td>0.884253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1000320</td>\n",
       "      <td>0.747453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1000425</td>\n",
       "      <td>0.759921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_ID  similarity\n",
       "0        1000001    1.000000\n",
       "62       1000063    0.750298\n",
       "92       1000093    0.708946\n",
       "161      1000162    0.714471\n",
       "200      1000201    0.759645\n",
       "245      1000246    0.701282\n",
       "307      1000308    0.884253\n",
       "319      1000320    0.747453\n",
       "424      1000425    0.759921"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df[sim_df['similarity'] > 0.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e187f-b027-4bd4-bae7-a4596ba74322",
   "metadata": {},
   "source": [
    "Now it is the time to export our data and vectorizer file to use it to compare our new user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fe80a1e-96a6-47da-9424-03a56b2873f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(vectorizer, \"./../models/tfidf_vectorizer.pkl\")\n",
    "sparse.save_npz(\"./../models/tfidf_matrix.npz\", TF_IDF_matrix)\n",
    "df.to_pickle(\"./../models/users_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39358456-cd97-4fcc-a531-2af8c712ea7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Obtaining dependency information for geopy from https://files.pythonhosted.org/packages/e5/15/cf2a69ade4b194aa524ac75112d5caac37414b20a3a03e6865dfe0bd1539/geopy-2.4.1-py3-none-any.whl.metadata\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Obtaining dependency information for geographiclib<3,>=1.52 from https://files.pythonhosted.org/packages/9f/5a/a26132406f1f40cf51ea349a5f11b0a46cec02a2031ff82e391c2537247a/geographiclib-2.0-py3-none-any.whl.metadata\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993ff185-25bf-4d11-865a-ee957b1aa08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('M9A1M9, Canada',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 466, in _make_request\n",
      "    six.raise_from(e, None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 461, in _make_request\n",
      "    httplib_response = conn.getresponse()\n",
      "                       ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/http/client.py\", line 1378, in getresponse\n",
      "    response.begin()\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/http/client.py\", line 318, in begin\n",
      "    version, status, reason = self._read_status()\n",
      "                              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/http/client.py\", line 279, in _read_status\n",
      "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/ssl.py\", line 1311, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/ssl.py\", line 1167, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 714, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "                       ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 468, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 357, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/requests/adapters.py\", line 486, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 826, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 826, in urlopen\n",
      "    return self.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/urllib3/connectionpool.py\", line 798, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/urllib3/util/retry.py\", line 592, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=M9A1M9%2C+Canada&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=10)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/geopy/adapters.py\", line 482, in _request\n",
      "    resp = self.session.get(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/requests/sessions.py\", line 602, in get\n",
      "    return self.request(\"GET\", url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/requests/sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/requests/sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/requests/adapters.py\", line 519, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=M9A1M9%2C+Canada&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=10)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/geopy/extra/rate_limiter.py\", line 136, in _retries_gen\n",
      "    yield i  # Run the function.\n",
      "    ^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/geopy/extra/rate_limiter.py\", line 274, in __call__\n",
      "    res = self.func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/geopy/geocoders/nominatim.py\", line 297, in geocode\n",
      "    return self._call_geocoder(url, callback, timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/geopy/geocoders/base.py\", line 368, in _call_geocoder\n",
      "    result = self.adapter.get_json(url, timeout=timeout, headers=req_headers)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/geopy/adapters.py\", line 472, in get_json\n",
      "    resp = self._request(url, timeout=timeout, headers=headers)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/heart_prediction_env/lib/python3.11/site-packages/geopy/adapters.py\", line 494, in _request\n",
      "    raise GeocoderUnavailable(message)\n",
      "geopy.exc.GeocoderUnavailable: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=M9A1M9%2C+Canada&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=10)\"))\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "import csv \n",
    "import time\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geo_app\", timeout=10)  # Increased timeout\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=2)  # 2-second delay\n",
    "\n",
    "with open('./../data/postalcodes.csv', 'r') as f_in, open('./../data/postalcodes_new.csv', 'w') as f_out:\n",
    "    reader = csv.reader(f_in)\n",
    "    writer = csv.writer(f_out)\n",
    "    writer.writerow(['postal_code', 'lat', 'lng'])\n",
    "    next(reader)  # Skip header\n",
    "\n",
    "    for row in reader:\n",
    "        try:\n",
    "            # Clean the postal code\n",
    "            postal_code = row[0].replace('\\xa0', '').replace(' ', '')  # Fix spaces\n",
    "            location = geocode(f\"{postal_code}, Canada\")\n",
    "            \n",
    "            if location:\n",
    "                writer.writerow([postal_code, location.latitude, location.longitude])\n",
    "            else:\n",
    "                writer.writerow([postal_code, \"Not found\", \"Not found\"])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error for {postal_code}: {str(e)}\")\n",
    "            writer.writerow([postal_code, \"Error\", \"Error\"])\n",
    "            time.sleep(5)  # Wait longer if an error occurs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloud_env",
   "language": "python",
   "name": "cloud_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
